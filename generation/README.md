This directory helps you finetune and evaluate GPT2 on the whiskey reviews dataset.
## Finetuning GPT2 for review generation
[finetune_whiskeyreviews.py](finetune_whiskeyreviews.py) takes the dataset named `data.csv` stored in [the ../dataset directory](../dataset) (look there to know how to generate that), which should have the following columns:
* whiskey: the name of the whiskey
* rating: int out of 100
* price: int in dollars
* review: text review

And generates a dataset formatted for GPT2 storing it in [../dataset/finetune](../dataset/finetune). The directory will have a `train.csv`, `val.csv`, and `test.csv` by the end of the script. The ratio of samples for each of them is controlled using the `ftrain, fval, ftest` constants.

Each of the csv's has one column called `text` where each row represents one review in the following format
```
f"<price>{row['price']}<rating>{row['rating']}<whiskey>{row['whiskey']}<review>{row['review']}"
```

These files will be then fed into the huggingface GPT2 trainer.

The script also generates a command for you to run which navigates to the [../transformers/examples/language-modeling](../transformers/examples/language-modeling) directory and starts training there with the trainer arguments shown in the command.

After running the training command, you end up with the following
* `finetuned-model-train` directory which houses the training parameters and end results as well as all the checkpoints kept during training and the final model.
* `finetued-model-logs` contains the logs of the training loop. You can use Tensorboard to visualize it by running `tensorboard --logdir finetued-model-logs --bind_all`.

For reference, I ran the training command as generated by `finetune_whiskeyreviews.py` (shown below) for 5 epochs on two Azure K-80's for 31 minutes yielding a final `perplexity = 15.4905`.
```
python -m torch.distributed.launch --nproc_per_node 2 run_clm.py
    --output_dir ../../../generation/finetuned-model-train/ 
    --model_type gpt2 --model_name_or_path gpt2 
    --validation_file ../../../dataset/finetune/val.csv 
    --do_eval --do_train 
    --train_file ../../../dataset/finetune/train.csv 
    --per_device_eval_batch_size 2 
    --per_device_train_batch_size 2 
    --num_train_epochs 5 
    --evaluation_strategy epoch 
    --logging_steps 4 
    --logging_dir ../../../generation/finetued-model-logs 
    --save_strategy epoch 
    --dataloader_num_workers 4
```

